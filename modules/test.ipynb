{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[{'title': 'Banana - Wikipedia', 'href': 'https://en.wikipedia.org/wiki/Banana', 'body': '\\n\\nA banana is an elongated, edible fruit – botanically a berry[1][2] – produced by several kinds of large herbaceous flowering plants in the genus Musa.[3] In some countries, bananas used for cooking may be called \"plantains\", distinguishing them from dessert bananas. The fruit is variable in size, color, and firmness, but is usually elongated and curved, with soft flesh rich in starch covered with a rind, which may be green, yellow, red, purple, or brown when ripe. The fruits grow upward in clusters near the top of the plant. Almost all modern edible seedless (parthenocarp) bananas come from two wild species\\xa0– Musa acuminata and Musa balbisiana. The scientific names of most cultivated bananas are Musa acuminata, Musa balbisiana, and Musa × paradisiaca for the hybrid Musa acuminata × M.\\xa0balbisiana, depending on their genomic constitution. The old scientific name for this hybrid, Musa sapientum, is no longer used.\\n\\nMusa species are native to tropical Indomalaya and Australia, and are li'}, {'title': 'Banana | Description, History, Cultivation, Nutrition, …', 'href': 'https://www.britannica.com/plant/banana-plant', 'body': 'Our editors will review what you’ve submitted and determine whether to revise the article.\\nOur editors will review what you’ve submitted and determine whether to revise the article.\\nbanana,  fruit of the genus Musa, of the family Musaceae, one of the most important fruit crops of the world. The banana is grown in the tropics, and, though it is most widely consumed in those regions, it is valued worldwide for its flavour, nutritional value, and availability throughout the year. Cavendish, or dessert, bananas are most commonly eaten fresh, though they may be fried or mashed and chilled in pies or puddings. They may also be used to flavour muffins, cakes, or breads. Cooking varieties, or plantains, are starchy rather than sweet and are grown extensively as a staple food source in tropical regions; they are cooked when ripe or immature. A ripe fruit contains as much as 22 percent of carbohydrate and is high in dietary fibre, potassium, manganese, and vitamins B6 and C.\\nBananas are thought '}, {'title': 'Bananas 101: Nutrition Facts and Health Benefits', 'href': 'https://www.healthline.com/nutrition/foods/b…', 'body': 'OUR BRANDS'}]\n"
     ]
    }
   ],
   "source": [
    "from search_utils import web_search\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "result = web_search(\"what is banana\", search_engine='bing', max_results=3)\n",
    "# print(web_search(\"Sodium magnesium sulfate\", search_engine='wikipedia', max_results=3))#, search_site='wikipedia.org'))\n",
    "print(len(result))#, search_site='wikipedia.org'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Apple Inc. | History, Products, Headquarters, & Facts',\n",
       "  'href': 'https://www.britannica.com/topic/Apple-Inc',\n",
       "  'body': 'Apple Inc., American manufacturer of personal computers, smartphones, tablet computers, computer peripherals, and computer software and one of the most recognizable brands in the world. It was the first successful personal computer company and the popularizer of the graphical user interface. Headquarters are located in Cupertino, California.'},\n",
       " {'title': 'Apple - Wikipedia',\n",
       "  'href': 'https://en.wikipedia.org/wiki/Apple',\n",
       "  'body': 'An apple is a round, edible fruit produced by an apple tree ( Malus spp., among them the domestic or orchard apple; Malus domestica ). Apple trees are cultivated worldwide and are the most widely grown species in the genus Malus. The tree originated in Central Asia, where its wild ancestor, Malus sieversii, is still found.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\31477\\.conda\\envs\\langchain\\lib\\site-packages\\curl_cffi\\aio.py:192: UserWarning: Curlm alread closed! quitting from process_data\n",
      "  warnings.warn(\"Curlm alread closed! quitting from process_data\")\n"
     ]
    }
   ],
   "source": [
    "web_search(\"what is apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_api_key = ''\n",
    "os.environ.update({\"OPENAI_API_KEY\": openai_api_key})\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a 15-year-old girl from the United States. I'm a student at a middle school. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class 1, Grade 7. I'm in Class\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen1.5-0.5B\"\n",
    "\n",
    "max_new_tokens = 500\n",
    "temperature = 0.1\n",
    "\n",
    "device = 'cuda'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device\n",
    ").to(device).eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # llama不支持fast\n",
    "    use_fast=False if model.config.model_type == 'llama' else True\n",
    ")\n",
    "\n",
    "text = \"Hello, who are you?\"\n",
    "\n",
    "def qwen_response(model, tokenizer, text):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=True,\n",
    "            temperature=temperature\n",
    "        )\n",
    "    outputs = outputs.tolist()[0][len(input_ids[0]):]\n",
    "    response = tokenizer.decode(outputs)\n",
    "    response = response.strip()\n",
    "    \n",
    "    return response \n",
    "\n",
    "print(qwen_response(model, tokenizer, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Any\n",
    "from langchain_core.callbacks import (\n",
    "    CallbackManagerForLLMRun,\n",
    ")\n",
    "from langchain_core.language_models import BaseChatModel, SimpleChatModel\n",
    "from langchain_core.messages import AIMessage, BaseMessage\n",
    "from langchain_core.outputs import ChatGeneration, ChatResult\n",
    "\n",
    "class QwenChatModel(BaseChatModel):\n",
    "    \"\"\"\n",
    "    Simple Qwen Chat Model.\n",
    "    这里有个比较矛盾的地方，记录一下。首先，BaseMessage 是一个 Union，类型为 str 或者 List(Union(str, dict))。但是在此处使用的时候，后文定义的正则处理函数指定了 model 的 output 类型强制为 str，所以这里把 output_str 写成 list 的形式就会报错。改成单条 string 了。\n",
    "    \"\"\"\n",
    "    def messages_to_str(\n",
    "        self,\n",
    "        messages: List[BaseMessage],    \n",
    "    ) -> List[str]:\n",
    "        str_messages = []\n",
    "        for msg in messages:\n",
    "            if type(msg.content) == list:\n",
    "                for m in msg.content:\n",
    "                    str_messages.append(str(m))\n",
    "            else:\n",
    "                str_messages.append(str(msg.content))\n",
    "        \n",
    "        return str_messages\n",
    "\n",
    "    def _generate(\n",
    "        self,\n",
    "        messages: List[BaseMessage],\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> ChatResult:\n",
    "        # output_str = []\n",
    "        # for msg in self.messages_to_str(messages):\n",
    "        #     response =  qwen_response(model, tokenizer, msg)# self._call(messages, stop=stop, run_manager=run_manager, **kwargs)\n",
    "        #     output_str.append(response)\n",
    "        # print(f\"type:{type(output_str)}, content:{output_str}\")\n",
    "        # message = AIMessage(content=output_str)\n",
    "        output_str = qwen_response(model, tokenizer, self.messages_to_str(messages)[0])\n",
    "        message = AIMessage(content=output_str)\n",
    "        generation = ChatGeneration(message=message)\n",
    "\n",
    "        return ChatResult(generations=[generation])\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Get the type of language model used by this chat model.\"\"\"\n",
    "        return \"qwen-chat-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = QwenChatModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    "    Tool,\n",
    ")\n",
    "from langchain.chains import LLMChain # from langchain.chains.base import Chain\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish # langchain_core.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_tool(search):\n",
    "    result_list = web_search(search, search_engine='wikipedia', max_results=2)\n",
    "    result = \"\"\n",
    "    for i, r in enumerate(result_list):\n",
    "        result += r['title']+\"\\n\"+r['body']+\"\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"WebSearch\",\n",
    "        func=web_search_tool,\n",
    "        description=\"useful for searching results from web\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the following questions by searching informations on Internet. You need to figure out what knowledge you need to answer the questions and generate the corresponding queries to look up on the Internet using a search engine.\n",
    "After you generate the corresponding query, you should search it. The results will be returned in string. \n",
    "Summarize results in natural language.\n",
    "\n",
    "When generating query:\n",
    "* Try to avoid any non-alphabetical symbols if possible\n",
    "* Never end the query in question mark\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question for which you must provide a natural language answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LLMSingleActionAgent' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat will happen if I throw a piece of sodium into water?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LLMSingleActionAgent' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "agent.invoke(\"what will happen if I throw a piece of sodium into water?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: the water will be affected by the sodium\n",
      "Action: the action to take, should be one of [WebSearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what will happen if I throw a piece of sodium into water?\n",
      "Thought: the water will be affected by the sodium\n",
      "Action: the action to take, should be one of [WebSearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what will happen if I throw a piece of sodium into water?\n",
      "Thought: the water will be affected by the sodium\n",
      "Action: the action to take, should be one of [WebSearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what will happen if I throw a piece of sodium into water?\n",
      "Thought: the water will be affected by the sodium\n",
      "Action: the action to take, should be one of [WebSearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what will happen if I throw a piece of sodium into water?\n",
      "Thought: the water will be affected by the sodium\n",
      "Action: the action to take, should be one of [WebSearch]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what will happen if I throw a piece of sodium into water?\n",
      "Thought: the water will be affected by the sodium\n",
      "Action: the action\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the final answer to the original input question\\n\\nQuestion: what will happen if I throw a piece of sodium into water?\\nThought: the water will be affected by the sodium\\nAction: the action'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what will happen if I throw a piece of sodium into water?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out what happens when sodium is put in water\n",
      "Action: WebSearch\n",
      "Action Input: \"sodium reaction with water\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mSodium | Facts, Uses, & Properties | Britannica\n",
      "sodium (Na), chemical element of the alkali metal group (Group 1 [Ia]) of the periodic table. Sodium is a very soft silvery-white metal. Sodium is the most common alkali metal and the sixth most abundant element on Earth, comprising 2.8 percent of Earth's crust. It occurs abundantly in nature in compounds, especially common salt —sodium ...\n",
      "Sodium - Wikipedia\n",
      "Many salts of sodium are highly water-soluble: sodium ions have been leached by the action of water from the Earth's minerals over eons, and thus sodium and chlorine are the most common dissolved elements by weight in the oceans. Sodium was first isolated by Humphry Davy in 1807 by the electrolysis of sodium hydroxide.\n",
      "\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSodium reacts with water to form sodium hydroxide and hydrogen gas\n",
      "Final Answer: When you throw a piece of sodium into water, it will react to form sodium hydroxide and hydrogen gas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'When you throw a piece of sodium into water, it will react to form sodium hydroxide and hydrogen gas.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\31477\\.conda\\envs\\langchain\\lib\\site-packages\\curl_cffi\\aio.py:192: UserWarning: Curlm alread closed! quitting from process_data\n",
      "  warnings.warn(\"Curlm alread closed! quitting from process_data\")\n"
     ]
    }
   ],
   "source": [
    "agent_executor.run(\"what will happen if I throw a piece of sodium into water?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"When you throw a piece of sodium into water, it will react vigorously with the water, producing hydrogen gas and heat. The reaction is so vigorous that it may even ignite the hydrogen gas, resulting in a fiery explosion. This is because sodium is a highly reactive metal, and it undergoes a violent exothermic reaction with water, forming sodium hydroxide and releasing hydrogen gas.\\n\\nIt's important to note that this is a highly dangerous experiment and should not be attempted without proper safety precautions and supervision. Sodium should only be handled by individuals with the necessary expertise and experience in handling reactive metals.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a useful assistant with great amount of chemical knowledge.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what will happen if I throw a piece of sodium into water?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
